{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings, nltk, re, distance\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from fuzzywuzzy import fuzz\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout   \n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import scikitplot as skplt\n",
    "import joblib\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, LSTM\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Training Data\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.sample(n=100000).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Null/NA values\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Test Data\n",
    "test = pd.read_csv('test.csv')\n",
    "test = test.sample(n=100000).reset_index(drop=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean and standardize the text data\n",
    "def processText(question):\n",
    "    \n",
    "    # Converts the input text to lowercase and removes any leading or trailing whitespace.\n",
    "    question = str(question).lower().strip()\n",
    "\n",
    "    # Replacements for Special Characters and Symbols.\n",
    "    question = question.replace('%',' percent ')\n",
    "    question = question.replace('$',' dollar ')\n",
    "    question = question.replace('£',' pound ')\n",
    "    question = question.replace('₹', ' rupee ')\n",
    "    question = question.replace('€', ' euro ')\n",
    "    question = question.replace('@', ' at ')\n",
    "    question = question.replace('[math]','')\n",
    "    question = question.replace(',000,000,000 ', 'b ')\n",
    "    question = question.replace(',000,000 ', 'm ')\n",
    "    question = question.replace(',000 ', 'k ')\n",
    "    \n",
    "    # Numeric abbreviations.\n",
    "    question = re.sub(r'([0-9]+)000000000', r'\\1b', question)\n",
    "    question = re.sub(r'([0-9]+)000000', r'\\1m', question)\n",
    "    question = re.sub(r'([0-9]+)000', r'\\1k', question)\n",
    "\n",
    "\n",
    "    # Contraction Expansions.\n",
    "    contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "\n",
    "    decontracted_question = []\n",
    "\n",
    "    for word in question.split():\n",
    "      if word in contractions:\n",
    "        word = contractions[word]\n",
    "      decontracted_question.append(word)\n",
    "    \n",
    "    question = ' '.join(decontracted_question)\n",
    "    question = question.replace(\"'ve\", \" have\")\n",
    "    question = question.replace(\"n't\", \" not\")\n",
    "    question = question.replace(\"'re\", \" are\")\n",
    "    question = question.replace(\"'ll\", \" will\")\n",
    "    question = re.sub(r\"[^A-Za-z0-9]\", \" \", question)\n",
    "    question = re.sub('[,\\.\\(\\)?\"\\']',\" \",question)\n",
    "    question = re.sub(r\"what's\", \"\", question)\n",
    "    question = re.sub(r\"What's\", \"\", question)\n",
    "    question = re.sub(r\"\\'s\", \" \", question)\n",
    "    question = re.sub(r\"\\'ve\", \" have \", question)\n",
    "    question = re.sub(r\"can't\", \"cannot \", question)\n",
    "    question = re.sub(r\"n't\", \" not \", question)\n",
    "    question = re.sub(r\"I'm\", \"I am\", question)\n",
    "    question = re.sub(r\" m \", \" am \", question)\n",
    "    question = re.sub(r\"\\'re\", \" are \", question)\n",
    "    question = re.sub(r\"\\'d\", \" would \", question)\n",
    "    question = re.sub(r\"\\'ll\", \" will \", question)\n",
    "    question = re.sub(r\"\\0k \", \"0000 \", question)\n",
    "    question = re.sub(r\" e g \", \" eg \", question)\n",
    "    question = re.sub(r\" b g \", \" bg \", question)\n",
    "    question = re.sub(r\"\\0s\", \"0\", question)\n",
    "    question = re.sub(r\" 9 11 \", \"911\", question)\n",
    "    question = re.sub(r\"e-mail\", \"email\", question)\n",
    "    question = re.sub(r\"\\s{2,}\", \" \", question)\n",
    "    question = re.sub(r\"quikly\", \"quickly\", question)\n",
    "    question = re.sub(r\" usa \", \" America \", question)\n",
    "    question = re.sub(r\" USA \", \" America \", question)\n",
    "    question = re.sub(r\" u s \", \" America \", question)\n",
    "    question = re.sub(r\" uk \", \" England \", question)\n",
    "    question = re.sub(r\" UK \", \" England \", question)\n",
    "    question = re.sub(r\"india\", \"India\", question)\n",
    "    question = re.sub(r\"china\", \"China\", question)\n",
    "    question = re.sub(r\"chinese\", \"Chinese\", question) \n",
    "    question = re.sub(r\"imrovement\", \"improvement\", question)\n",
    "    question = re.sub(r\"intially\", \"initially\", question)\n",
    "    question = re.sub(r\"quora\", \"Quora\", question)\n",
    "    question = re.sub(r\" dms \", \"direct messages \", question)  \n",
    "    question = re.sub(r\"demonitization\", \"demonetization\", question) \n",
    "    question = re.sub(r\"actived\", \"active\", question)\n",
    "    question = re.sub(r\"kms\", \" kilometers \", question)\n",
    "    question = re.sub(r\"KMs\", \" kilometers \", question)\n",
    "    question = re.sub(r\" cs \", \" computer science \", question) \n",
    "    question = re.sub(r\" upvotes \", \" up votes \", question)\n",
    "    question = re.sub(r\" iPhone \", \" phone \", question)\n",
    "    question = re.sub(r\"\\0rs \", \" rs \", question) \n",
    "    question = re.sub(r\"calender\", \"calendar\", question)\n",
    "    question = re.sub(r\"ios\", \"operating system\", question)\n",
    "    question = re.sub(r\"gps\", \"GPS\", question)\n",
    "    question = re.sub(r\"gst\", \"GST\", question)\n",
    "    question = re.sub(r\"programing\", \"programming\", question)\n",
    "    question = re.sub(r\"bestfriend\", \"best friend\", question)\n",
    "    question = re.sub(r\"dna\", \"DNA\", question)\n",
    "    question = re.sub(r\"III\", \"3\", question) \n",
    "    question = re.sub(r\"the US\", \"America\", question)\n",
    "    question = re.sub(r\"Astrology\", \"astrology\", question)\n",
    "    question = re.sub(r\"Method\", \"method\", question)\n",
    "    question = re.sub(r\"Find\", \"find\", question) \n",
    "    question = re.sub(r\"banglore\", \"Banglore\", question)\n",
    "    question = re.sub(r\" J K \", \" JK \", question)\n",
    "\n",
    "    # Eliminate HTML tags\n",
    "    question = BeautifulSoup(question)\n",
    "    question = question.get_text()\n",
    "\n",
    "    # Remove punctuation characters\n",
    "    pattern = re.compile('\\W')\n",
    "    question = re.sub(pattern,' ',question).strip()\n",
    "    \n",
    "    return question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The progress_apply() method is used to apply a function to each element in a Series (column) of a DataFrame while providing a progress bar to track the progress of the operation.(Refer From Stackoverflow)\n",
    "\n",
    "tqdm.pandas()  # Enable progress bar for pandas apply\n",
    "train.question1 = train.question1.progress_apply(processText)\n",
    "train.question2 = train.question2.progress_apply(processText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The progress_apply() method is used to apply a function to each element in a Series (column) of a DataFrame while providing a progress bar to track the progress of the operation.\n",
    "\n",
    "tqdm.pandas()  # Enable progress bar for pandas apply\n",
    "test.question1 = test.question1.progress_apply(processText)\n",
    "test.question2 = test.question2.progress_apply(processText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each text entry\n",
    "train['q1_len'] = train.question1.apply(len)\n",
    "train['q2_len'] = train.question2.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding number of words in each question\n",
    "train['q1_num_words'] = train.question1.apply(lambda sent: len(sent.split()))\n",
    "train['q2_num_words'] = train.question2.apply(lambda sent: len(sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a row of data as input and finds the number of common words\n",
    "# between two questions in that row.\n",
    "\n",
    "def find_common_words(row):\n",
    "    # Convert the words in 'question1' to lowercase and create a set to store them.\n",
    "    words_set1 = set(map(lambda word: word.lower().strip(), row['question1'].split()))\n",
    "    \n",
    "    # Convert the words in 'question2' to lowercase and create a set to store them.\n",
    "    words_set2 = set(map(lambda word: word.lower().strip(), row['question2'].split()))\n",
    "    \n",
    "    # Calculate the number of common words between the two sets.\n",
    "    common_word_count = len(words_set1 & words_set2)\n",
    "    \n",
    "    # Return the count of common words.\n",
    "    return common_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'train' is a DataFrame, this line of code applies the 'find_common_words' function\n",
    "# to each row in the DataFrame and creates a new column 'common_words' to store the results.\n",
    "train['common_words'] = train.apply(find_common_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['q1_len'] = test.question1.apply(len)\n",
    "test['q2_len'] = test.question2.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['q1_num_words'] = test.question1.apply(lambda sent: len(sent.split()))\n",
    "test['q2_num_words'] = test.question2.apply(lambda sent: len(sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['common_words'] = test.apply(find_common_words,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the total number of words in two questions of a row in a DataFrame.\n",
    "\n",
    "def calculate_total_words(row):\n",
    "    # Convert the words in 'question1' to lowercase and create a set to store them.\n",
    "    words_set1 = set(map(lambda word: word.lower().strip(), row['question1'].split()))\n",
    "    \n",
    "    # Convert the words in 'question2' to lowercase and create a set to store them.\n",
    "    words_set2 = set(map(lambda word: word.lower().strip(), row['question2'].split()))\n",
    "    \n",
    "    # Calculate the total number of words by adding the lengths of the two sets.\n",
    "    total_word_count = len(words_set1) + len(words_set2)\n",
    "    \n",
    "    # Return the total word count.\n",
    "    return total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the 'calculate_total_words' function to each row in the DataFrame and creates a new column 'total_words' to store the results.\n",
    "train['total_words'] = train.apply(calculate_total_words, axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame to show the results.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #The 'shared_words' column quantifies the similarity between pairs of questions by calculating the ratio of shared words to the total number of words in those questions. \n",
    " #This measure can help in understanding the textual similarity between different pairs of questions and can potentially be used as a feature for further analysis or modeling purposes.\n",
    "\n",
    "train['shared_words'] = round(train.common_words / train.total_words,2)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['total_words'] = test.apply(calculate_total_words,axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['shared_words'] = round(test.common_words / test.total_words,2)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes token-based features for two input questions in a row.\n",
    "\n",
    "def compute_token_similarity_features(row):\n",
    "    # Extract the text of 'question1' and 'question2'.\n",
    "    ques1 = row['question1']\n",
    "    ques2 = row['question2']\n",
    "    \n",
    "    # A small constant to avoid division by zero.\n",
    "    epsilon = 0.0001\n",
    "    \n",
    "    # Initialize an array to store the token-based features.\n",
    "    token_features = np.zeros((8,), 'float32')\n",
    "    \n",
    "    # Calculate the lengths of 'question1' and 'question2'.\n",
    "    q1_len, q2_len = len(ques1), len(ques2)\n",
    "    \n",
    "    # Split the questions into tokens.\n",
    "    tokens_ques1 = ques1.split()\n",
    "    tokens_ques2 = ques2.split()\n",
    "    \n",
    "    # Check if either of the questions has no tokens.\n",
    "    if len(tokens_ques1) == 0 or len(tokens_ques2) == 0:\n",
    "        return token_features\n",
    "    \n",
    "    # Create sets of non-stopwords and stopwords for both questions.\n",
    "    non_stopwords_q1 = set([word for word in tokens_ques1 if word not in stopwords.words('english')])\n",
    "    non_stopwords_q2 = set([word for word in tokens_ques2 if word not in stopwords.words('english')])\n",
    "\n",
    "    stopwords_q1 = set([word for word in tokens_ques1 if word in stopwords.words('english')])\n",
    "    stopwords_q2 = set([word for word in tokens_ques2 if word in stopwords.words('english')])\n",
    "    \n",
    "    # Calculate the counts of common non-stopwords, stopwords, and tokens.\n",
    "    common_word_count = len(non_stopwords_q1.intersection(non_stopwords_q2))\n",
    "    common_stop_count = len(stopwords_q1.intersection(stopwords_q2))\n",
    "    common_token_count = len(set(tokens_ques1).intersection(set(tokens_ques2)))\n",
    "    \n",
    "    # Calculate the token-based features.\n",
    "    token_features[0] = common_word_count / (min(q1_len, q2_len) + epsilon)\n",
    "    token_features[1] = common_word_count / (max(q1_len, q2_len) + epsilon)\n",
    "    token_features[2] = common_stop_count / (min(q1_len, q2_len) + epsilon)\n",
    "    token_features[3] = common_stop_count / (max(q1_len, q2_len) + epsilon)\n",
    "    token_features[4] = common_token_count / (min(q1_len, q2_len) + epsilon)\n",
    "    token_features[5] = common_token_count / (max(q1_len, q2_len) + epsilon)\n",
    "    token_features[6] = int(tokens_ques1[0] == tokens_ques2[0])\n",
    "    token_features[7] = int(tokens_ques1[-1] == tokens_ques2[-1])\n",
    "    \n",
    "    return token_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referred from Kaggle Notebook.\n",
    "token_features = train.progress_apply(compute_token_similarity_features,axis=1)\n",
    "\n",
    "train['cwc_min'] = list(map(lambda x: x[0], token_features))\n",
    "train['cwc_max'] = list(map(lambda x: x[1], token_features))\n",
    "train['csc_min'] = list(map(lambda x: x[2], token_features))\n",
    "train['csc_max'] = list(map(lambda x: x[3], token_features))\n",
    "train['ctc_min'] = list(map(lambda x: x[4], token_features))\n",
    "train['ctc_max'] = list(map(lambda x: x[5], token_features))\n",
    "train['first_word_same'] = list(map(lambda x: x[6], token_features))\n",
    "train['last_word_same'] = list(map(lambda x: x[7], token_features))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_features = test.progress_apply(compute_token_similarity_features,axis=1)\n",
    "\n",
    "test['cwc_min'] = list(map(lambda x: x[0], token_features))\n",
    "test['cwc_max'] = list(map(lambda x: x[1], token_features))\n",
    "test['csc_min'] = list(map(lambda x: x[2], token_features))\n",
    "test['csc_max'] = list(map(lambda x: x[3], token_features))\n",
    "test['ctc_min'] = list(map(lambda x: x[4], token_features))\n",
    "test['ctc_max'] = list(map(lambda x: x[5], token_features))\n",
    "test['first_word_same'] = list(map(lambda x: x[6], token_features))\n",
    "test['last_word_same'] = list(map(lambda x: x[7], token_features))\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes length-based features for two input questions in a row.\n",
    "\n",
    "def compute_length_similarity_features(row):   \n",
    "    # Extract the text of 'question1' and 'question2'.\n",
    "    ques1 = row['question1']\n",
    "    ques2 = row['question2']  \n",
    "    \n",
    "    # Initialize an array to store the length-based features.\n",
    "    length_features = np.zeros((3,), 'float32')\n",
    "    \n",
    "    # Split the questions into tokens.\n",
    "    q1_tokens = ques1.split()\n",
    "    q2_tokens = ques2.split()\n",
    "    \n",
    "    # Check if either of the questions has no tokens.\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "\n",
    "    # Calculate the absolute difference in token count between the two questions.\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    # Calculate the average token count between the two questions.\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens)) / 2\n",
    "    \n",
    "    # Find the common substrings between the two questions and normalize by the length of the shorter question.\n",
    "    strs = list(distance.lcsubstrings(ques1, ques2))\n",
    "    length_features[2] = len(strs) / (min(len(ques1), len(ques2)) + 1) \n",
    "    \n",
    "    return length_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate length-based features for each row in the 'train' DataFrame.\n",
    "length_features = train.progress_apply(compute_length_similarity_features, axis=1)\n",
    "\n",
    "# Extract and assign specific length-based features to new columns.\n",
    "train['mean_question_length'] = list(map(lambda x: x[0], length_features))\n",
    "train['absolute_length_difference'] = list(map(lambda x: x[1], length_features))\n",
    "train['longest_common_substring_ratio'] = list(map(lambda x: x[2], length_features))\n",
    "\n",
    "# Display the updated DataFrame with the new length-based features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_features_test = test.progress_apply(compute_length_similarity_features,axis=1)\n",
    "\n",
    "test['mean_question_length'] = list(map(lambda x: x[0], length_features_test))\n",
    "test['absolute_length_difference'] = list(map(lambda x: x[1], length_features_test))\n",
    "test['longest_common_substring_ratio'] = list(map(lambda x: x[2], length_features_test))\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates fuzzy matching features for two input questions in a row.\n",
    "\n",
    "def compute_fuzzy_matching_features(row):\n",
    "    # Extract the text of 'question1' and 'question2'.\n",
    "    ques1 = row['question1']\n",
    "    ques2 = row['question2']\n",
    "\n",
    "    # Initialize an array to store the fuzzy matching features.\n",
    "    fuzzy_features = np.zeros((4,), 'float32')\n",
    "\n",
    "    # Calculate the fuzzy ratio between the two questions.\n",
    "    fuzzy_features[0] = fuzz.QRatio(ques1, ques2)\n",
    "\n",
    "    # Calculate the partial fuzzy ratio between the two questions.\n",
    "    fuzzy_features[1] = fuzz.partial_ratio(ques1, ques2)\n",
    "\n",
    "    # Calculate the token set ratio between the two questions.\n",
    "    fuzzy_features[2] = fuzz.token_set_ratio(ques1, ques2)\n",
    "\n",
    "    # Calculate the token sort ratio between the two questions.\n",
    "    fuzzy_features[3] = fuzz.token_sort_ratio(ques1, ques2)\n",
    "\n",
    "    return fuzzy_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fuzzy matching features for each row in the 'train' DataFrame.\n",
    "fuzzy_features = train.progress_apply(compute_fuzzy_matching_features, axis=1)\n",
    "\n",
    "# Extract and assign specific fuzzy matching features to new columns.\n",
    "train['fuzzy_ratio'] = list(map(lambda x: x[0], fuzzy_features))\n",
    "train['fuzzy_partial_ratio'] = list(map(lambda x: x[1], fuzzy_features))\n",
    "train['token_set_ratio'] = list(map(lambda x: x[2], fuzzy_features))\n",
    "train['token_sort_ratio'] = list(map(lambda x: x[3], fuzzy_features))\n",
    "\n",
    "# Display the updated DataFrame with the new fuzzy matching features.\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz_features_test = test.progress_apply(compute_fuzzy_matching_features,axis=1)\n",
    "\n",
    "test['fuzzy_ratio'] = list(map(lambda x: x[0],fuzz_features_test))\n",
    "test['fuzzy_partial_ratio'] = list(map(lambda x: x[1],fuzz_features_test))\n",
    "test['token_set_ratio'] = list(map(lambda x: x[2],fuzz_features_test))\n",
    "test['token_sort_ratio'] = list(map(lambda x: x[3],fuzz_features_test))\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cwc_min: Feature representing the minimum common word count between two questions.\n",
    "#cwc_max: Feature representing the maximum common word count between two questions.\n",
    "#ctc_min: Feature representing the minimum common token count between two questions.\n",
    "#ctc_max: Feature representing the maximum common token count between two questions.\n",
    "#csc_min: Feature representing the minimum common stop word count between two questions.\n",
    "#csc_max: Feature representing the maximum common stop word count between two questions.\n",
    "#is_duplicate: Target variable indicating whether the question pair is a duplicate (1) or not (0).\n",
    "#hue='is_duplicate': This parameter specifies that the 'is_duplicate' column will be used to color-code the data points in the pair plot.\n",
    "#In other words, it allows us to differentiate between duplicate and non-duplicate question pairs based on colors.\n",
    "\n",
    "#The scatter plots can show how similar or dissimilar feature values are for duplicate and non-duplicate pairs. \n",
    "#Clusters or patterns in the scatter plots can indicate the discriminatory power of features in classifying question pairs.\n",
    "#The histograms show the distribution of individual features, giving insight into their ranges and variations.\n",
    "#The diagonal axis shows the kernel density estimate, which gives a smoothed representation of the distribution of each feature.\n",
    "\n",
    "sns.pairplot(train[['cwc_min','cwc_max','ctc_min','ctc_max','csc_min','csc_max','is_duplicate']], hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_word_same: A feature representing whether the first word of both questions in a pair is the same (1) or not (0).\n",
    "#last_word_same: A feature representing whether the last word of both questions in a pair is the same (1) or not (0).\n",
    "#is_duplicate: The target variable indicating whether the question pair is a duplicate (1) or not (0).\n",
    "#hue='is_duplicate': This parameter assigns the 'is_duplicate' column as the basis for color-coding the data points in the pair plot. \n",
    "#By using this parameter, the code allows you to visually distinguish between duplicate and non-duplicate question pairs using different colors.\n",
    "\n",
    "#The scatter plots will indicate how the values of 'first_word_same' and 'last_word_same' vary for both duplicate and non-duplicate question pairs.\n",
    "#Clusters or trends in these scatter plots can provide insights into how these features contribute to the classification.\n",
    "#The histograms will illustrate the distribution of each feature, showing the frequency and spread of values.\n",
    "\n",
    "sns.pairplot(train[['first_word_same','last_word_same','is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['mean_ques_len', 'abs_len_diff', 'longest_sub_ratio', 'is_duplicate']]: This section of the code selects specific columns from the 'train' DataFrame.\n",
    "#The columns selected are as follows:\n",
    "#mean_ques_len: A feature representing the average length of tokens in both questions in a pair.\n",
    "#abs_len_diff: A feature representing the absolute difference in the number of tokens between the two questions in a pair.\n",
    "#longest_sub_ratio: A feature representing the ratio of the length of the longest common substring to the minimum of the lengths of the two questions in a pair.\n",
    "#is_duplicate: The target variable indicating whether the question pair is a duplicate (1) or not (0).\n",
    "#hue='is_duplicate': This parameter assigns the 'is_duplicate' column as the basis for color-coding the data points in the pair plot. By using this parameter, the code allows you to visually distinguish between duplicate and non-duplicate question pairs using different colors.\n",
    "\n",
    "sns.pairplot(train[['mean_question_length','absolute_length_difference','longest_common_substring_ratio','is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['fuzz_ratio', 'fuzz_partial_ratio', 'token_set_ratio', 'token_sort_ratio', 'is_duplicate']]: This part of the code selects specific columns from the 'train' DataFrame. The columns selected are as follows:\n",
    "\n",
    "#fuzz_ratio: A feature representing the fuzz ratio, which measures the similarity between two strings based on different matching criteria.\n",
    "#fuzz_partial_ratio: A feature representing the fuzz partial ratio, which focuses on partial matching between two strings.\n",
    "#token_set_ratio: A feature representing the token set ratio, which measures the similarity between two strings based on their token sets.\n",
    "#token_sort_ratio: A feature representing the token sort ratio, which measures the similarity between two strings based on sorted tokens.\n",
    "#is_duplicate: The target variable indicating whether the question pair is a duplicate (1) or not (0).\n",
    "#hue='is_duplicate': This parameter assigns the 'is_duplicate' column as the basis for color-coding the data points in the pair plot. This color coding allows you to visually differentiate between duplicate and non-duplicate question pairs.\n",
    "\n",
    "\n",
    "#Scatter plots visually represent the relationship between feature values and the 'is_duplicate' label for both duplicate and non-duplicate question pairs.\n",
    "#Histograms illustrate the distribution of each feature, providing insights into their values' frequency and spread.\n",
    "\n",
    "sns.pairplot(train[['fuzzy_ratio','fuzzy_partial_ratio','token_set_ratio','token_sort_ratio','is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The MinMaxScaler is a popular technique for transforming features to a specific range, typically [0, 1].\n",
    "\n",
    "#scaled_train = scaler.fit_transform(...): This line applies the MinMaxScaler to a subset of features in the 'train' dataset. The features being scaled are:\n",
    "#cwc_min: Minimum common word count\n",
    "#cwc_max: Maximum common word count\n",
    "#ctc_min: Minimum common token count\n",
    "#ctc_max: Maximum common token count\n",
    "#csc_min: Minimum common stop word count\n",
    "#csc_max: Maximum common stop word count\n",
    "#first_word_same: Whether the first word is the same\n",
    "#last_word_same: Whether the last word is the same\n",
    "#abs_len_diff: Absolute length difference\n",
    "#mean_ques_len: Mean question length\n",
    "#longest_sub_ratio: Longest common substring ratio\n",
    "#fuzz_ratio: Fuzzy string matching ratio\n",
    "#fuzz_partial_ratio: Fuzzy partial string matching ratio\n",
    "#token_set_ratio: Token set matching ratio\n",
    "#token_sort_ratio: Token sort matching ratio\n",
    "#The .fit_transform() method of the scaler scales the selected features and returns a new array scaled_train containing the scaled values.\n",
    "\n",
    "#target_train = train.is_duplicate.values: In this line, the target variable 'is_duplicate' is extracted from the 'train' dataset and converted into a NumPy array.\n",
    "#This prepares the target variable for further analysis, such as model training and evaluation.\n",
    "\n",
    "#Overall, this showcases the application of feature scaling using the MinMaxScaler to specific features in the 'train' dataset. \n",
    "#Feature scaling is important for ensuring that the features are on a similar scale, which can improve the performance of machine learning algorithms that are sensitive to feature magnitudes. \n",
    "#The scaled features, stored in scaled_train, and the target variable, stored in target_train, are now ready to be used for building and training machine learning models.\n",
    "\n",
    "\n",
    "mm_scaler = MinMaxScaler()\n",
    "scaled_train = mm_scaler.fit_transform(train[['cwc_min','cwc_max','ctc_min','ctc_max','csc_min','csc_max','first_word_same','last_word_same','absolute_length_difference','mean_question_length','longest_common_substring_ratio','fuzzy_ratio','fuzzy_partial_ratio','token_set_ratio','token_sort_ratio']])\n",
    "target_train = train.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaled_test = mm_scaler.fit_transform(test[['cwc_min','cwc_max','ctc_min','ctc_max','csc_min','csc_max','first_word_same','last_word_same','absolute_length_difference','mean_question_length','longest_common_substring_ratio','fuzzy_ratio','fuzzy_partial_ratio','token_set_ratio','token_sort_ratio']])\n",
    "target_test = test.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An instance of the PCA class is created. The PCA class from the scikit-learn library is used for performing Principal Component Analysis. The parameters are as follows:\n",
    "\n",
    "#n_components=2: This parameter specifies the number of principal components to retain after the transformation. In this case, the data will be reduced to a 2-dimensional space.\n",
    "#random_state=101: This parameter sets the random seed for reproducibility. The same random seed ensures that the results will be consistent across different runs.\n",
    "#X_train_pca = pca.fit_transform(scaled_train): This line applies PCA transformation to the scaled features of the 'train' dataset (scaled_train). \n",
    "#The .fit_transform() method of the PCA class computes the principal components and performs the dimensionality reduction. The result is stored in the variable X_train_pca.\n",
    "#X_train_pca: This new variable holds the transformed data after applying PCA. The data is now represented in a lower-dimensional space, with each row representing a data point and each column corresponding to a principal component.\n",
    "#PCA works by finding orthogonal axes (principal components) along which the variance of the data is maximized. \n",
    "#The first principal component accounts for the most variance, the second for the second most, and so on. \n",
    "#By choosing only a few principal components (in this case, 2), the code reduces the data's dimensionality while retaining the most important information.\n",
    "#The resulting X_train_pca can be used for various purposes, such as visualization, clustering, or as input features for machine learning models.\n",
    "#By reducing the data to only two dimensions, you can create scatter plots or visualizations to gain insights into the structure and patterns within the data.\n",
    "\n",
    "pca = PCA(n_components=2,random_state=101)\n",
    "X_train_pca = pca.fit_transform(scaled_train)\n",
    "X_test_pca = pca.fit_transform(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size for the scatter plot.\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a scatter plot using the first two principal components from X_train_pca.\n",
    "# 'X_train_pca[:, 0]' represents the first principal component, and 'X_train_pca[:, 1]'\n",
    "# represents the second principal component. 'c=target_train' colors the points based on\n",
    "# their corresponding target labels.\n",
    "\n",
    "fig = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=target_train)\n",
    "\n",
    "# Add a legend to the plot. 'fig.legend_elements()[0]' extracts legend handles and\n",
    "# 'labels=list([0,1])' specifies the labels for the legend.\n",
    "\n",
    "plt.legend(handles=fig.legend_elements()[0], labels=list([0, 1]))\n",
    "\n",
    "# Display the scatter plot.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "fig = plt.scatter(X_test_pca[:,0],X_train_pca[:,1],c=target_test)\n",
    "plt.legend(handles=fig.legend_elements()[0],labels=list([0,1]))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_train_data = train.drop(['id','qid1','qid2','question1','question2'],axis=1)\n",
    "rest_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_test_data = test.drop(['id','qid1','qid2','question1','question2'],axis=1)\n",
    "rest_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_train_df = train[['question1','question2']]\n",
    "ques_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_test_df = test[['question1','question2']]\n",
    "ques_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all questions from 'ques_train_df' into a single array.\n",
    "questions_train = np.array(list(ques_train_df.question1) + list(ques_train_df.question2))\n",
    "\n",
    "# Create a CountVectorizer with a maximum of 500 features (words).\n",
    "cv = CountVectorizer(max_features=500)\n",
    "\n",
    "# Transform and convert the text data from 'questions_train' into a numerical format.\n",
    "# The 'toarray()' method converts the result into a numerical array.\n",
    "# Split the transformed data into two arrays, one for 'question1' and one for 'question2'.\n",
    "ques1_train_arr, ques2_train_arr = np.vsplit(cv.fit_transform(questions_train).toarray(), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_test = np.array(list(ques_test_df.question1) + list(ques_test_df.question2))\n",
    "cv = CountVectorizer(max_features=500)\n",
    "ques1_test_arr, ques2_test_arr = np.vsplit(cv.fit_transform(questions_test).toarray(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame 'question1_df' from the numerical representations of 'question1'.\n",
    "question1_df = pd.DataFrame(ques1_train_arr)\n",
    "\n",
    "# Create a DataFrame 'question2_df' from the numerical representations of 'question2'.\n",
    "question2_df = pd.DataFrame(ques2_train_arr)\n",
    "\n",
    "# Concatenate the two DataFrames 'question1_df' and 'question2_df' side by side.\n",
    "# This combines the numerical representations of both questions into a single DataFrame.\n",
    "questions_train_df = pd.concat([question1_df, question2_df], axis=1)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame 'questions_train_df'.\n",
    "questions_train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_test_df = pd.DataFrame(ques1_test_arr)\n",
    "question2_test_df = pd.DataFrame(ques2_test_arr)\n",
    "ques_test_df = pd.concat([question1_test_df, question2_test_df], axis=1)\n",
    "ques_test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_train_df.index = rest_train_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_test_df.index = rest_test_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([rest_train_data,questions_train_df],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([rest_test_data,ques_test_df],axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('is_duplicate',axis=1)\n",
    "X.columns = X.columns.astype(str)\n",
    "y = df_train.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,shuffle=True,random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop('is_duplicate',axis=1)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "y_test = df_test.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns of the training data 'X_train' to ensure they are of string data type.\n",
    "X_train.columns = X.columns.astype(str)\n",
    "\n",
    "# Extract the feature names from the DataFrame and store them in the 'features' variable.\n",
    "features = X_train.columns\n",
    "\n",
    "# Scale the training data using the previously fitted scaler ('scaler').\n",
    "# This transforms the data so that it has zero mean and unit variance for each feature.\n",
    "scaled_X_train = mm_scaler.fit_transform(X_train)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame while preserving the feature names.\n",
    "# This allows us to work with the scaled data in a more interpretable way.\n",
    "scaled_X_train = pd.DataFrame(scaled_X_train, columns=features)\n",
    "\n",
    "# Display the first few rows of the scaled training data DataFrame.\n",
    "scaled_X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_val = mm_scaler.fit_transform(X_val)\n",
    "scaled_X_val = pd.DataFrame(scaled_X_val,columns=features)\n",
    "scaled_X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = mm_scaler.transform(X_test)\n",
    "scaled_X_test = pd.DataFrame(scaled_X_test,columns=features)\n",
    "scaled_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define a function to plot a confusion matrix\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, class_labels=None):\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # If class_labels are not provided, create numerical labels based on unique values\n",
    "    if class_labels is None:\n",
    "        class_labels = np.unique(np.concatenate((true_labels, predicted_labels)))\n",
    "    \n",
    "    # Create a heatmap for the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "\n",
    "    # Add labels, title, and axis ticks\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xticks(np.arange(len(class_labels)) + 0.5, class_labels)\n",
    "    plt.yticks(np.arange(len(class_labels)) + 0.5, class_labels)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Define a function to plot the precision-recall curve\n",
    "def plot_precision_recall_curve(y_true, y_prob):\n",
    "    \n",
    "    # Compute precision and recall values and the area under the curve (AUC)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    average_precision = auc(recall, precision)\n",
    "\n",
    "    # Create a new figure for the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot the precision-recall curve as a step plot\n",
    "    plt.step(recall, precision, color='b', alpha=0.8, where='post')\n",
    "    \n",
    "    # Fill the area under the curve with a transparent color\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "\n",
    "    # Add labels and set limits for the axes\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "\n",
    "    # Set the title of the plot to include the Average Precision (AP) score\n",
    "    plt.title(f'Precision-Recall Curve (AP={average_precision:.2f})')\n",
    "    \n",
    "    # Enable the grid for better readability\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a  model\n",
    "def train_model(model):\n",
    "    # Train the model on the scaled training data and corresponding labels\n",
    "    model.fit(scaled_X_train, y_train)\n",
    "    \n",
    "    # Calculate and print the validation accuracy\n",
    "    accuracy = model.score(X_val, y_val)\n",
    "    print(\"Validation Accuracy:\", accuracy)\n",
    "    \n",
    "    # Make predictions on the scaled test data\n",
    "    pred = model.predict(scaled_X_test)\n",
    "    \n",
    "    # Print a classification report to evaluate model performance\n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    # Plot a confusion matrix to visualize classification results\n",
    "    plot_confusion_matrix(y_test, pred)\n",
    "    \n",
    "    # Plot a precision-recall curve to assess precision and recall trade-offs\n",
    "    plot_precision_recall_curve(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a Logistic Regression model using the train_model function.\n",
    "train_model(LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a RandomForestClassifier model using the train_model function.\n",
    "train_model(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a DecisionTreeClassifier model using the train_model function.\n",
    "train_model(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a LinearSVC model using the train_model function.\n",
    "train_model(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a GradientBoostingClassifier model using the train_model function.\n",
    "train_model(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a AdaBoostClassifier model using the train_model function.\n",
    "train_model(AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create an Artificial Neural Network (ANN) model\n",
    "def create_neural_network_model():\n",
    "    # Create a sequential model for the ANN\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add a dense layer with 32 units and ReLU activation function\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    \n",
    "    # Add another dense layer with 64 units and ReLU activation function\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    \n",
    "    # Add a third dense layer with 128 units and ReLU activation function\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    \n",
    "    # Add a dropout layer with a dropout rate of 0.28\n",
    "    model.add(Dropout(0.28))\n",
    "    \n",
    "    # Add a final dense layer with 1 unit and sigmoid activation function for binary classification\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model with binary cross-entropy loss and the Adam optimizer\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_neural_network_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback to prevent overfitting by monitoring validation accuracy.\n",
    "# It will stop training if validation accuracy doesn't improve for 40 consecutive epochs.\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=40, verbose=1)\n",
    "\n",
    "# Define the ReduceLROnPlateau callback to adjust the learning rate during training.\n",
    "# It monitors validation accuracy and reduces the learning rate by a factor of 0.1 if there's no improvement for 5 consecutive epochs.\n",
    "rl = ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, verbose=2, min_lr=0.001, factor=0.1)\n",
    "\n",
    "# Train the ANN model with the specified callbacks.\n",
    "# It trains for 50 epochs, using a batch size of 32, and validates on the validation dataset.\n",
    "# The callbacks, including EarlyStopping and ReduceLROnPlateau, are applied during training.\n",
    "ann_model = model.fit(scaled_X_train,\n",
    "                     y_train,\n",
    "                     epochs=50,\n",
    "                     batch_size=32,\n",
    "                     validation_data=(scaled_X_val, y_val),\n",
    "                     callbacks=[es, rl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for the loss plot with a specified figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the training loss in red ('r') and label it as 'train loss'\n",
    "plt.plot(ann_model.history['loss'], 'r', label='train loss')\n",
    "\n",
    "# Plot the validation loss in blue ('b') and label it as 'test loss'\n",
    "plt.plot(ann_model.history['val_loss'], 'b', label='test loss')\n",
    "\n",
    "# Add labels to the x and y axes\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Loss Graph')\n",
    "\n",
    "# Add a legend to the plot to distinguish between training and validation loss curves\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referred by Kaggle Notebook\n",
    "# Create a figure for the accuracy plot with a specified figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the training accuracy in red ('r') and label it as 'train accuracy'\n",
    "plt.plot(ann_model.history['accuracy'], 'r', label='train accuracy')\n",
    "\n",
    "# Plot the validation accuracy in blue ('b') and label it as 'test accuracy'\n",
    "plt.plot(ann_model.history['val_accuracy'], 'b', label='test accuracy')\n",
    "\n",
    "# Add labels to the x and y axes\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Accuracy Graph')\n",
    "\n",
    "# Add a legend to the plot to distinguish between training and validation accuracy curves\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the scaled test data (scaled_X_test) and corresponding labels (y_test)\n",
    "loss, acc = model.evaluate(scaled_X_test, y_test)\n",
    "\n",
    "# Print the test loss\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a Convolutional Neural Network (CNN) model\n",
    "def create_cnn_model(input_shape, filters, kernel_size, pool_size):\n",
    "    # Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add a 1D convolutional layer with specified filters and kernel size, using ReLU activation\n",
    "    model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    # Add a max pooling layer with the specified pool size\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    \n",
    "    # Flatten the output of the convolutional layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add a dense layer with 128 units and ReLU activation\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # Add a final dense layer with 1 unit and sigmoid activation for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 64\n",
    "kernel_size = 3\n",
    "pool_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = create_cnn_model(input_shape=(scaled_X_train.shape[1], 1),filters=filters, kernel_size=kernel_size, pool_size=pool_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train.shape\n",
    "scaled_X_train_expand = np.expand_dims(scaled_X_train, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_val.shape\n",
    "scaled_X_val_expand = np.expand_dims(scaled_X_val, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_val_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy',mode='max',patience=40,verbose=1)\n",
    "\n",
    "rl = ReduceLROnPlateau(monitor='val_accuracy',mode='max',patience=5,verbose=2,min_lr=0.001,factor=0.1)\n",
    "\n",
    "model_cnn = cnn_model.fit(scaled_X_train_expand,\n",
    "         y_train,\n",
    "         epochs=50,\n",
    "         batch_size=32,\n",
    "         validation_data=(scaled_X_val_expand,y_val),\n",
    "         callbacks=[es,rl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(model_cnn.history['loss'],'r',label='train loss')\n",
    "plt.plot(model_cnn.history['val_loss'],'b',label='test loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(model_cnn.history['accuracy'],'r',label='train accuracy')\n",
    "plt.plot(model_cnn.history['val_accuracy'],'b',label='test accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = cnn_model.evaluate(scaled_X_test,y_test)\n",
    "print(\"Test Loss:\",loss)\n",
    "print(\"Test Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "def create_rnn_model(input_shape, units):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units, activation='tanh',kernel_initializer = GlorotUniform(), input_shape=input_shape))\n",
    "    model.add(Dense(128, activation='tanh'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64\n",
    "input_shape=(scaled_X_train.shape[1], 1)\n",
    "rnn_model = create_rnn_model(input_shape, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train.shape\n",
    "scaled_X_train_expand = np.expand_dims(scaled_X_train, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=40, verbose=1)\n",
    "rl = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, verbose=2, min_lr=0.001, factor=0.1)\n",
    "\n",
    "\n",
    "model_rnn = rnn_model.fit(scaled_X_train_expand,\n",
    "         y_train,\n",
    "         epochs=50,\n",
    "         batch_size=32,\n",
    "         validation_data=(scaled_X_val_expand,y_val),\n",
    "         callbacks=[es,rl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(model_rnn.history['loss'],'r',label='train loss')\n",
    "plt.plot(model_rnn.history['val_loss'],'b',label='test loss')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(model_rnn.history['accuracy'],'r',label='train accuracy')\n",
    "plt.plot(model_rnn.history['val_accuracy'],'b',label='test accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = rnn_model.evaluate(scaled_X_test,y_test)\n",
    "print(\"Test Loss:\",loss)\n",
    "print(\"Test Accuracy:\",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
